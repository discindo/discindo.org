{
  "hash": "c30b85fdd6887f777955e25c76c1fe14",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: A simple workflow for async {shiny} with {mirai}\nauthor:\n  - name: teo\n    url: \"https://discindo.org/authors/teofil\"\nexecute:\n  eval: false\ndate: '2024-01-15'\ncategories: [R, Shiny, async programming, mirai, daemons, parallelization, shiny module]\ndescription: >\n  A module-based approach to simplify async calls in `{shiny}` apps using `{mirai}`\n---\n\n\n\n\n[![](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/J3J8133RYV)\n\nIn my [previous post](https://discindo.org/post/an-opiniated-workflow-for-async-shiny-with-callr/),\nI developed a `shiny` module to encapsulate the logic of sending and monitoring background async\ntasks. The main advantage of this approach was to simplify making repeated async calls\nin larger applications. In the first version of this module, the async process was\ncreated with `callr:r_bg`, an approach that [my self](https://discindo.org/post/asynchronous-execution-in-shiny/) and\n[others](https://hypebright.nl/index.php/2023/09/12/async-programming-in-shiny-with-crew-and-callr/) have used before.\n\nHowever, there is one, potentially significant, drawback of using `callr` in such\na way. Take this hypotetical scenario as an example. You have a shiny app with\nfive async tasks triggered in response to a user changing a dataset. You test it locally,\nand everything works great. Then you deploy and share with the world. Ten of your\nfollowers click on the link more-or-less at the same time and visit the application,\neach choosing one of three datasets available in your data science app. The app's\n`server`, featuring `async` functions gets to work, and initializes 5 (tasks) \\* 10 (users)\n= 50 `callr::r_bg` calls, each running in a separate child R process. Some of these\ncopy nothing the child enviroment, some only a few small objects, but others a large\ndata object needed for the async function to transform or run a model. It should be no surprise\nif the app is no longer that fast. The hosting server, even with a fast, multi-thread\nprocessor, still hast to contend with many `R` processes and the `shiny` session\nis also getting a bit bogged down, as it has potentially dozens of observers monitoring\nbackground processes. Clearly, we need to rethink our approach.\n\nWouldn't it be great if we had a way to limit the total number of concurrent\nchild `R` processes that our `shiny` session would spawn, and have a queue system\nthat would start another background job as soon as one completes? Enter\n[`mirai`](https://github.com/shikokuchuo/mirai). `mirai` lets us initialize a set\nnumber of `R` `daemons` (persistent background processes) that are\nready to receive `mirai` requests and ensures FIFO (first in, first out) scheduling.\nUsing `mirai`, we can handle a large number of async background jobs elegantly\nwithout overburdening the system. If the number of jobs requested by the `shiny`\napp exceeds the number of available `daemons`, `mirai` would hold the jobs until\none of the daemons (threads) frees up and submit on a first-come, first-serve\nbasis. Just great!\n\n## So how does it work?\n\nFor example setups for `shiny`, check out the documentation, where you can read\nabout [`mirai`-only](https://shikokuchuo.net/mirai/articles/shiny.html#shiny-example-usage)\nsolutions, as well as approaches combining\n[`mirai` with `promises`](https://shikokuchuo.net/mirai/articles/shiny.html#example-using-promises).\n\nFor my application, I'll adapt the `callr` approach I described in my\n[previous post](https://discindo.org/post/an-opiniated-workflow-for-async-shiny-with-callr/)\nto work with `mirai`. In fact, there very little to change to make the `callr`\nexample work with `mirai`:\n\n1. Change the `async` version of our function to use `mirai`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead_six <- function(x, sleep) {\n  Sys.sleep(sleep)\n  head(x)\n}\n\nhead_six_async_mirai <- function(x, sleep) {\n  args <- list(head_six = head_six, x = x, sleep = sleep)\n  bg_process <- mirai::mirai(.expr = head_six(x, sleep), .args = args)\n  return(bg_process)\n}\n```\n:::\n\n\n\n\n2. Change the polling logic in the module's server to use `mirai::unresolved`,\n   rather than the `is_alive` method of the `callr` process object.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_async_srv_mirai <- function(id, fun_async, fun_args, wait_for_event = FALSE, verbose = FALSE) {\n  moduleServer( id, function(input, output, session){\n    res_rct <- shiny::reactiveVal(NULL)\n    poll_rct <- shiny::reactiveVal(TRUE)\n\n    if (isTRUE(wait_for_event)) {\n      poll_rct(FALSE)\n    }\n\n    bg_job <- reactive({\n      req(isTRUE(poll_rct()))\n      do.call(fun_async, fun_args)\n    }) |> bindEvent(poll_rct())\n\n    observe({\n      req(isTRUE(poll_rct()))\n      invalidateLater(250)\n      if (verbose) {\n        message(sprintf(\"checking: %s\", id))\n      }\n\n      alive <- mirai::unresolved(bg_job())\n      if (isFALSE(alive)) {\n        res_rct(bg_job()$data)\n        if (verbose) {\n          message(sprintf(\"done: %s\", id))\n        }\n        poll_rct(FALSE)\n      }\n    })\n\n    return(list(\n      start_job = function() poll_rct(TRUE),\n      get_result = reactive(res_rct())\n    ))\n\n  })\n}\n```\n:::\n\n\n\n\n3. In the app's `server`, or better yet `global.R` or equivalents, we need to\n   initialize the `daemons`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  mirai::daemons(2L)\n  onStop(function() mirai::daemons(0L))\n```\n:::\n\n\n\n\nIn this setup, our shiny can run up to two parallel async jobs handled by the\n`mirai` queue. These `daemons` are shared across _all users_ of our application,\nirrespective of the `shiny` session. This is because `mirai`'s daemons apply to\nthe entire `R` session, not individual `shiny` sessions.\n\n## Gist\n\nFor a running example of `mirai` async with the module, visit this gist:\n\n<script src=\"https://gist.github.com/teofiln/59e69133e2ce08597b071ffa1cad5dc9.js\"></script>\n\n## Summary\n\nIn this post I went over an approach to organize `mirai` background async jobs using\na `shiny` module, in order to make the async code faster to write, less error prone\nand overall cleaner.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}