{
  "hash": "e82aafa320cf5183d5522e3400805b96",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Using R and {paws} to populate DynamoDB tables\nauthors: ['teo']\nexecute:\n  eval: false\ndate: '2022-04-30'\nslug: []\ncategories:\n  - R\ntags:\n  - paws\n  - aws\n  - dynamodb\nimages: []\n---\n\n\n\n\n\n\n# R and AWS DynamoDB\n\nIn recent weeks we've been using AWS services for a few our projects. One of the things\nthat came up was to populate `DynamoDB` tables with data from `R`. Of course, we\ndidn't have to do this from `R`, but most of our data analysis and reporting stack\nis based on `R`, so why not keep it all in the same environment. We were surprised, however,\nthat there are very limited resources on how to put data into `DynamoDB` from `R`. A quick\nGoogle search with these keywords did not reveal any tutorials or blogposts, which are\nusually plentiful for many other topics in the excellent `R` community. \n\nTo our knowledge so far, there are two `R` packages designed to interact with\n`{DynamoDB}`. One is the [`{aws.dynamodb}`](https://github.com/cloudyr/aws.dynamodb) \npackage by `cloudyr` that is no longer maintained. The other option is of course,\n[`{paws}`](https://paws-r.github.io/) -- a comprehensive `R` SDK for AWS,\nwhich provides access to over 150 AWS services through `R`. `{paws}`' documentation is \nextensive, including its coverage of the features of `DynamoDB` endpoints. So, it was \nstraightforward to write a few functions wrapping `paws::dynamodb`, to make it easier to \nput all the rows of a data.frame as items in `DynamoDB`.\n\n# Loading items into a `DynamoDB` table from `R` using the `paws` SDK\n\n`DynamoDB`'s `put_item` API query requires a JSON with the following format:\n\n```\n  Item={\n    'AlbumTitle': {\n      'S': 'Somewhat Famous',\n    },\n    'Artist': {\n      'S': 'No One You Know',\n    },\n    'SongTitle': {\n      'S': 'Call Me Today',\n      }\n    }\n```\n\nIn `R` terms this would translate to a named nested list with sublists further named\nwith the field's data type as described in the [documentation](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.NamingRulesDataTypes.html#HowItWorks.DataTypes): \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  AlbumTitle = list(S = \"Somewhat Famous\"),\n  Artist = list(S = \"No One You Know\"),\n  SongTitle = list(S = \"Call Me Today\")\n)\n```\n:::\n\n\n\n\n\nTo write a function to bulk load a data frame into `DynamoDB` using the `R SDK` `{paws}`,\nwe follow the next steps, each with its own `R` function:\n\n1. Guess the appropriate field type (attribute) for a data.frame column\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nguess_attrib <- function(types) {\n  # add more as needed\n  switch(types,\n         \"numeric\" = \"N\",\n         \"integer\" = \"N\",\n         \"character\" = \"S\",\n         \"logical\" = \"BOOL\")\n}\n```\n:::\n\n\n\n\n\n2. Format the named nested list for a single row of the data.frame, which would become a `DynamoDB` item\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndynamo_item_prep <- function(.item) {\n  types <- lapply(.item, class)\n  attribs <- lapply(types, guess_attrib)\n  nested <- lapply(seq_along(.item), function(i) as.list(setNames(.item[[i]], attribs[[i]])))\n  setNames(nested, names(.item))\n}\n```\n:::\n\n\n\n\n\n3. Wrap the `dynamodb_put_item` function (exported by `paws.database`) to put the formatted item in our remote table\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndynamo_item_put <- function(.con, .table, .prep) {\n  .con$put_item(\n    TableName = .table,\n    Item = .prep\n  )\n}\n```\n:::\n\n\n\n\n\nTo test this setup we load the `{paws}` package and create a connection to our `DynamoDB`:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- paws::dynamodb(\n  config = list(\n    credentials = list(\n      creds = list(\n        access_key_id = Sys.getenv(\"ACCESS_KEY_ID\"),\n        secret_access_key = Sys.getenv(\"SECRET_ACCESS_KEY\")\n      ),\n      profile = Sys.getenv(\"PROFILE\")\n    ),\n    region = Sys.getenv(\"REGION\")\n  )\n)\n```\n:::\n\n\n\n\n\nMeanwhile, our project `.Renviron` needs to have these entries set:\n\n```\nACCESS_KEY_ID = \"OURKEYID\"\nSECRET_ACCESS_KEY = \"OURSECRET\"\nPROFILE = \"default\"\nREGION = \"us-east-1\"\n```\n\nNow, if we have a DynamoDB table called `Iris` with a numeric partition key called ID,\nwe can use our functions to put items into it from `R`:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris_to_put <- iris\niris_to_put$Species <- as.character(iris_to_put$Species)\niris_to_put$ID <- 1:150\n\npreped_item <- dynamo_item_prep(.item = iris_to_put[1, ])\npreped_item\ndynamo_item_put(.con = con, .table = \"Iris\", .prep = preped_item)\n```\n:::\n\n\n\n\n\nFinally, we can wrap our functions to send a whole data.frame in one step:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndynamo_bulk_put <- function(.con, .table, .df) {\n  lapply(1:nrow(.df), function(i)\n    dynamo_item_prep(.item = .df[i, ]) |>\n      dynamo_item_put(.con = .con, .table = .table))\n}\n```\n:::\n\n\n\n\n\nThen, to send the whole `iris` table, we can run\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndynamo_bulk_put(.con = con, .table = \"Iris\", .df = iris_to_put)\n```\n:::\n\n\n\n\n\n## Next steps\n\nGreat! This worked pretty well, however, so far our setup only allows for simple data types.\nWe can't for example send a list as one of the item components, which is obviously important for a\nnoSQL database -- so far we haven't done anything more than sending a \"flat\" table. Also, our simple\nfunction doesn't yet know anything about our DynamoDB's throughput and capacity, so its going to \nnaively try to send all data even though the table provisioning on AWS might not be configured to \nreceive all the data in one go. Finally, there are other options in the `paws` SDK for writing larger\nvolume of data to DynamoDB. We'll explore some of these topics in future posts.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}