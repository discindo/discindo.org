{
  "hash": "4814d5d583d4b171a006e245b8c1740b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: How to dynamically aggregate any dataset in R with `purrr` and `dplyr`\nauthor: \n  - name: teo\n    url: \"https://discindo.org/authors/teo\"\ndate: '2025-02-06'\ncategories:\n  - R\n  - aggregate\n  - dynamic\n  - purrr\n  - dplyr\ndescription: \"Demo of an approach I use for dynamic aggregating of tables (in Shiny)\"\nexecute:\n  eval: false\nimage: \"images/image.png\"\n---\n\n\n[![](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/J3J8133RYV)\n\n\n::: {.cell}\n\n:::\n\n\nThis post continues what I started [last time](/posts/2025-01-31-filter-snippet), \nwhen I described an approach\nfor dynamic filtering of data frame in `R`. The motivation and approach are \nvery similar. In short, we want to have a function that takes a list with\ninstructions about how to aggregate a data frame. This is desirable in \nnon-interactive or automated workflows as in these cases we usually don't \nknow what the user might request. Creating a flexible interface, where\none can send a JSON with aggregation instructions therefore can be very \nhelpful for various `{shiny}` and `{plumber}` tasks.\n\n### Dynamic aggregation\n\nAs with the dynamic filter, we want something of the form:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n.aggregate(my_data, my_list_of_instructions)\n```\n:::\n\n\nFor aggregation to work, we need to specify at least one grouping variable,\nand then the names and aggregation functions for the columns we would like\nto summarize. So the instructions list should have the form:\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggr_list <- list(\n    groups = list(col = \"group_var\"),\n    aggregates = list(\n        list(col = \"column 1\", fun = \"mean\"),\n        list(col = \"column 2\", fun = \"sd\"),\n        ...\n    )\n)\n```\n:::\n\n\nTo show an example, we could get the mean, median, and standard deviation of\nSepal Length in species from the `iris` dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- iris\nl <- list(\n  groups = list(col = \"Species\"),\n  aggregates = list(\n    list(col = \"Sepal.Length\", fun = \"mean\"),\n    list(col = \"Sepal.Length\", fun = \"median\"),\n    list(col = \"Sepal.Length\", fun = \"sd\")\n  )\n)\n.aggregate(d, l)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(Species)`\nJoining with `by = join_by(Species)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Species Sepal.Length_mean Sepal.Length_median Sepal.Length_sd\n1     setosa              5.01                 5.0            0.35\n2 versicolor              5.94                 5.9            0.52\n3  virginica              6.59                 6.5            0.64\n```\n\n\n:::\n:::\n\n\nAs we can tell, we in the `aggregates list`, we can specify the same column \nmultiple times, and the resulting table will only contain the columns for\nwhich we've specified an aggregation.\n\nA more complex example would be to group on more than variable and summarize\nmultiple columns. For example, group by cylinder, gear and carburetor and \nfind the mean of miles per gallon, the total horse power and the median weight\nof cars in the `mtcars` dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- mtcars\nl <- list(\n  groups = list(col = c(\"cyl\", \"gear\", \"carb\")),\n  aggregates = list(\n    list(col = \"mpg\", fun = \"mean\"),\n    list(col = \"hp\", fun = \"sum\"),\n    list(col = \"wt\", fun = \"median\")\n  )\n)\n.aggregate(d, l)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(cyl, gear, carb)`\nJoining with `by = join_by(cyl, gear, carb)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   cyl gear carb mpg_mean hp_sum wt_median\n1    6    4    4    19.75    466      3.16\n2    4    4    1    29.10    290      2.07\n3    6    3    1    19.75    215      3.34\n4    8    3    2    17.15    650      3.48\n5    8    3    4    12.62   1140      5.25\n6    4    4    2    24.75    318      2.96\n7    8    3    3    16.30    540      3.78\n8    4    3    1    21.50     97      2.46\n9    4    5    2    28.20    204      1.83\n10   8    5    4    15.80    264      3.17\n11   6    5    6    19.70    175      2.77\n12   8    5    8    15.00    335      3.57\n```\n\n\n:::\n:::\n\n\nNeat. Again, the motivation here is not to replace the sweet `{dplyr}` syntax, \nrather to come up with a mechanism to do complex aggregation in one step, \nby creating an instructions list (or JSON) which, again, in `{shiny}` or `{plumber}`\ncontext would most likely be constructed programmatically.\n\n### How does it work?\n\nSimilar to our filtering function, we have two sections. First is input validation,\nagain using `{checkmate}` because it's awesome. We can make sure that the inputs \nare of correct type, that they are named, and that the columns specified as grouping\nand aggregation variables are present in the dataset. Likewise, we ensure that the \nrequested aggregation functions are supported. \n\nIn the second section, we first convert the string passed to `fun` to a function, \nso it can be used downstream in `dplyr::summarize`. We do this with a helper \nfunction that can be called at the time `summarize` executes. \n\nThen, we loop over the contents of the `aggregates` sub-list and apply each aggregation\nindependently resulting in a list of aggregated datasets. For example, if we specified\nthe mean, median, and sd for Sepal Length by Species, at this stage we would have a list\nof three data frames with the grouping column and another column representing the aggregate.\n\nFinally, to collate the tables we use `reduce` with `left_join`, essentially joining the\nthree data frames by species. \n\nNote the nice argument `.by` for `dplyr::summarize`. In this case we just send the string\nfrom the `groups$col` slot in our instructions list. i.e we don't need to use `dplyr::group_by`\nand the NSE construct it would require (converting it to symbol, and `!!` it). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Aggregate a dataset\n#' @param .data the data frame\n#' @param .arglist a list of column names to group by\n#' @examples\n#' d <- iris\n#' l <- list(\n#'   groups = list(col = \"Species\"),\n#'   aggregates = list(\n#'     list(col = \"Sepal.Length\", fun = \"mean\"),\n#'     list(col = \"Sepal.Width\", fun = \"mean\")\n#'   )\n#' )\n#' .aggregate(d, l)\n#' @return a data frame with the columns aggregated\n#' @export\n.aggregate <- function(.data, .arglist) {\n  checkmate::assert_data_frame(.data)\n  checkmate::assert_list(.arglist, types = \"list\")\n  checkmate::assert_named(.arglist)\n  checkmate::assert_subset(\n    names(.arglist),\n    choices = c(\"groups\", \"aggregates\")\n  )\n  checkmate::assert_list(.arglist$groups, len = 1)\n  checkmate::assert_subset(\n    purrr::pluck(.arglist, \"groups\", \"col\"),\n    choices = names(.data)\n  )\n  checkmate::assert_subset(\n    purrr::pluck(.arglist, \"aggregates\", \"col\"),\n    choices = names(.data)\n  )\n  checkmate::assert_subset(\n    purrr::pluck(.arglist, \"aggregates\", \"fun\"),\n    choices = c(\n      \"mean\", \"median\", \"sum\", \"min\", \"max\", \"sd\", \"var\", \"count\"\n    )\n  )\n\n  .get_aggr_fun <- function(x) {\n    switch(x,\n      \"mean\" = mean,\n      \"median\" = stats::median,\n      \"sum\" = sum,\n      \"min\" = min,\n      \"max\" = max,\n      \"sd\" = sd,\n      \"var\" = var,\n      \"count\" = length\n    )\n  }\n\n  aggr_dataset <- purrr::map(\n    .arglist$aggregates,\n    .f = ~ dplyr::summarise(\n      .data,\n      !!paste(.x$col, .x$fun, sep = \"_\") :=\n        .get_aggr_fun(.x$fun)(!!rlang::sym(.x$col)),\n      .by = .arglist$groups$col\n    )\n  ) |>\n    purrr::reduce(dplyr::left_join) |>\n    dplyr::mutate_if(is.numeric, round, 2)\n\n  aggr_dataset\n}\n```\n:::\n\n\nIn a `{shiny}` application, where we want to enable the user to select any column(s)\nto aggregate with some choices for aggregating function, it would require quite a bit\nof `if/else` logic to capture all the cases manually. Using this alternative, we simply\nharvest the user's selections from the input and construct the list of instructions before\nplugging it into `.aggregate` to obtain our results.\n\n### Summary\n\nIn this post, we explored a method for dynamically aggregating datasets in R using `purrr` \nand `dplyr`. We created a function `.aggregate` that takes a data frame and a list of \ninstructions specifying the grouping variables and the aggregation functions to apply. This \napproach is particularly useful in non-interactive or automated workflows, such as in `{shiny}` \napplications or `{plumber}` APIS, where the user might specify different aggregation requirements.\n\nWe demonstrated the usage of the `.aggregate` function with examples using the `iris` and \n`mtcars` datasets, showing how to group by one or more variables and apply various aggregation \nfunctions. The function ensures input validation using `{checkmate}` and dynamically applies \nthe specified aggregation functions, collating the results into a single data frame.\n\nThis method provides a flexible and efficient way to perform complex aggregations \nprogrammatically, reducing the need for extensive `if/else` logic and making it easier to \nhandle user-defined aggregation instructions.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}