{
  "hash": "9d92b5a60726e7f982eadd4abd456159",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: A plumber API to filter and aggregate datasets\nauthor: \n  - name: teo\n    url: \"https://discindo.org/authors/teo\"\ndate: '2025-02-13'\ncategories:\n  - R\n  - plumber\n  - API\n  - filter \n  - aggregate\n  - httr2\ndescription: \"Demo of a `{plumber}` that uses dynamic filtering and aggregation\"\nexecute:\n  eval: false\nimage: \"images/image.png\"\n---\n\n\n\n\n[![](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/J3J8133RYV)\n\nOver the past couple of weeks, I've been sharing some code that I use for dynamic\n[filtering](/posts/2025-01-31-filter-snippet) and [aggregation](/posts/2025-02-06-aggregate-snippet)\n of data frames in `R`. The idea of these functions was\nto have single-step methods for complex filter or aggregate queries. Each of the \nfunctions worked with a list of instructions, specifically formatted for the task.\nI adopted this approach to make it easier to use these functions in web applications\nor APIs. If the filter or aggregate query request can be sent as a list, then it can\nbe easily converted to JSON and used in API calls. \n\nIn this post, I am going to demo how we can integrate the functions from the previous\ntwo posts into a `{plumber}` API and, after deployment, have `/filter` and `/aggregate`\nendpoints available as a \"service\". \n\n### Plumber API for filter and aggregate\n\nThe `{plumber}` API is organized in the form of an `R` package. \n\n```\n├── DESCRIPTION\n├── inst\n│   └── plumber.r\n├── man\n│   ├── dot-aggregate.Rd\n│   ├── dot-filter.Rd\n│   └── run_api.Rd\n├── NAMESPACE\n├── plumb.ex.Rproj\n├── R\n│   ├── api.r\n│   └── funs.r\n└── test.r\n```\n\nThe `R` directory contains the script `funs.r` where I define the `.filter` and `.aggregate` \nfunctions I covered in the previous two posts. The `.api.r` script contains a single function\nthat starts the `API` on our preferred host and port (defaults to localhost and 5000).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' start plumber api\n#' @param host the host address\n#' @param port the port to use\n#' @importFrom plumber pr pr_run pr_get\n#' @export\nrun_api <- function(port = 5000, host = \"127.0.0.1\") {\n  path <- system.file(\"plumber.r\", package = \"plumb.ex\")\n  path |>\n    pr() |>\n    pr_run(port = port, host = host)\n}\n```\n:::\n\n\n\n\nThis is similar to `{golem}`'s `run_app()` function and it streamlines\nthe development cycle. Whenever I make updates to the underlying code in `funs.r`\nor the `{plumber}` endpoints in `inst/plumber.r`, I can run:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::document() # re-documents and loads all functions \nrun_api()\n```\n:::\n\n\n\n\nand that would start the API making it accessible at `http://127.0.0.1:5000`,\nwith the `{swagger}` interface for manual testing at `http://127.0.0.1:5000/__docs__/`.\nIt is then ready for queries.\n\n### Endpoints\n\nThe package exports the `.filter` and `.aggregate` functions. Then the API uses these\nwhen defining the endpoints. In this example API we have three endpoints defined in\n`inst/plumber.r`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plumber.R.\n\n#* @plumber\n#* @apiTitle Plumber filter or aggregate\n#* @apiDescription Plumber example for dynamic filtering and aggregation\n#* @apiVersion 1.0.0\nfunction(pr) {\n  pr |>\n    plumber::pr_set_serializer(plumber::serializer_unboxed_json())\n}\n\n#* Hello\n#* @get /hello\nfunction() {\n  \"Hello, there!\"\n}\n\n#* Filter\n#* @param data the name of the data frame to filter, `\"iris\"` or `\"mtcars\"`\n#* @param instructions_list a list of instructions for aggregation.\n#* @post /filter\nfunction(data, instructions_list) {\n  d <- get(data)\n  l <- jsonlite::fromJSON(instructions_list, simplifyVector = FALSE)\n  .filter(d, l)\n}\n\n#* Aggregate\n#* @param data the name of the data frame to aggregate, `\"iris\"` or `\"mtcars\"`\n#* @param instructions_list a list of instructions for aggregation.\n#* @post /aggregate\nfunction(data, instructions_list) {\n  d <- get(data)\n  l <- jsonlite::fromJSON(instructions_list, simplifyVector = FALSE)\n  .aggregate(d, l)\n}\n```\n:::\n\n\n\n\nThe first is `/hello` and is simply a health check endpoint. Using `httr2` we can make\nrequests to it as follows:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr$> library(jsonlite)\n    library(httr2)\n \n    request(\"http://127.0.0.1:5000/hello\") |>\n      req_perform() |>\n      resp_body_json()\n[1] \"Hello, there!\"\n```\n:::\n\n\n\n\nThe other two endpoints are simple wrappers around `.filter` and `.aggregate` to do two steps:\n\n1. get the dataset requested by the user. For simplicity in this example, the dataset \nargument is passed on as a string, and then we user `get` to get that dataset, assuming its\none of the ones prepackaged with `R`. But its easy to modify that and simply send JSON \ndata to the endpoint.\n\n2. convert the JSON received by the API into a list as required in `R`. This is needed because\nthe instructions list for filtering or aggregation is sent with the request as JSON, and the\nvalidation within our functions expects a list. One could relax these requirement as well by\nallowing a JSON string in the `instructions_list` argument and parsing this internally.\n\n### Interactive demo\n\n#### Start the API\n\nDuring development, we would run:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::document() # re-documents and loads all functions \nrun_api()\n```\n:::\n\n\n\n\nIf the `plumb.ex` package is installed, we would instead run:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plumb.ex) # re-documents and loads all functions \nplumb.ex::run_api(port = 6000)\n```\n:::\n\n\n\n\nIf its deployed, for one method see [this post](/posts/2024-02-25-how-to-set-up-development-and-production-environments-using-aws-copilot-example-using-a-plumber-api), \nwe follow the code below to make requests.\n\n#### Filter\n\nFrom `R` and `{shiny}` we can call the `/filter` endpoint using the following steps.\nFirst, we create our filter instructions, convert that to JSON, and finally use\n`httr` or `httr2` to make a request to the API:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(jsonlite)\nlibrary(httr2)\n\nfilter_data <- list(\n  list(col = \"Sepal.Length\", fun = \"between\", min = 4.9, max = 5),\n  list(col = \"Species\", fun = \"in\", val = c(\"setosa\", \"versicolor\"))\n)\n\nfilter_json <- jsonlite::toJSON(filter_data, auto_unbox = TRUE)\njsonlite::prettify(filter_json)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[\n    {\n        \"col\": \"Sepal.Length\",\n        \"fun\": \"between\",\n        \"min\": 4.9,\n        \"max\": 5\n    },\n    {\n        \"col\": \"Species\",\n        \"fun\": \"in\",\n        \"val\": [\n            \"setosa\",\n            \"versicolor\"\n        ]\n    }\n]\n \n```\n\n\n:::\n\n```{.r .cell-code}\nrequest(\"http://127.0.0.1:6000\") |>\n  req_url_path(\"filter\") |>\n  req_body_json(\n    data = list(data = \"iris\", instructions_list = filter_json),\n    auto_unbox = TRUE\n  ) |>\n  req_perform() |>\n  resp_body_json(simplifyVector = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1           4.9         3.0          1.4         0.2     setosa\n2           5.0         3.6          1.4         0.2     setosa\n3           5.0         3.4          1.5         0.2     setosa\n4           4.9         3.1          1.5         0.1     setosa\n5           5.0         3.0          1.6         0.2     setosa\n6           5.0         3.4          1.6         0.4     setosa\n7           4.9         3.1          1.5         0.2     setosa\n8           5.0         3.2          1.2         0.2     setosa\n9           4.9         3.6          1.4         0.1     setosa\n10          5.0         3.5          1.3         0.3     setosa\n11          5.0         3.5          1.6         0.6     setosa\n12          5.0         3.3          1.4         0.2     setosa\n13          4.9         2.4          3.3         1.0 versicolor\n14          5.0         2.0          3.5         1.0 versicolor\n15          5.0         2.3          3.3         1.0 versicolor\n```\n\n\n:::\n:::\n\n\n\n\n#### Aggregate\n\nSimilarly, for the `/aggregate` endpoint:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(jsonlite)\nlibrary(httr2)\n\naggregate_instructions <- list(\n  groups = list(col = \"Species\"),\n  aggregates = list(\n    list(col = \"Sepal.Length\", fun = \"mean\"),\n    list(col = \"Sepal.Width\", fun = \"mean\")\n  )\n)\n\naggregate_json <- jsonlite::toJSON(aggregate_instructions, auto_unbox = TRUE)\njsonlite::prettify(aggregate_json)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{\n    \"groups\": {\n        \"col\": \"Species\"\n    },\n    \"aggregates\": [\n        {\n            \"col\": \"Sepal.Length\",\n            \"fun\": \"mean\"\n        },\n        {\n            \"col\": \"Sepal.Width\",\n            \"fun\": \"mean\"\n        }\n    ]\n}\n \n```\n\n\n:::\n\n```{.r .cell-code}\nrequest(\"http://127.0.0.1:5000\") |>\n  req_url_path(\"aggregate\") |>\n  req_body_json(\n    data = list(data = \"iris\", instructions_list = aggregate_json),\n    auto_unbox = TRUE\n  ) |>\n  req_perform() |>\n  resp_body_json(simplifyVector = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Species Sepal.Length_mean Sepal.Width_mean\n1     setosa              5.01             3.43\n2 versicolor              5.94             2.77\n3  virginica              6.59             2.97\n```\n\n\n:::\n:::\n\n\n\n\n### How is this useful?\n\nI struggle with this sometimes my self. Isn't this why we have databases to begin with?\nOf course, having an API that queries a database would be preferable in most applications\nrequiring large amounts of data. However, sometimes we don't have the expertise, bandwidth,\nor budget for a database setup, or we could be working with local files, in `arrow`, `parquet`, `qs`\nor some other format where it might make sense or is justifiable to run the queries in `R` it self.\n\n### Summary\nIn this post, we demonstrated how to create a `{plumber}` API that provides endpoints for dynamic filtering and aggregation of datasets in `R`. We structured the API as an `R` package, defined the necessary functions, and set up the endpoints to handle JSON requests. We also provided examples of how to interact with the API using `httr2` from `R`. This approach can be useful for scenarios where a database setup is not feasible, and we need to work with data files directly in `R`.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}